{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c45acd0e-2ce5-41bd-8962-aab4b0c8caf8",
   "metadata": {
    "id": "c45acd0e-2ce5-41bd-8962-aab4b0c8caf8"
   },
   "source": [
    "# Google Workspace APIs\n",
    "Use Google's Workspace API (managed here https://console.cloud.google.com/) for various tasks.\n",
    "\n",
    "Credentials can be downloaded as `credentials.json` from the API Credentials and used to produce `token.json` for persistent use. OAuth 2.0 requires the redirect URI in the app and in the \"Flow\" - within the code - to be the same (the default port for localhost is 8080). It's also worth noting that for apps in \"testing,\" users need to be added via the OAuth consent screen, although in testing \"scope\" does not need to be specified in the API (it can be tested and switched in the code).\n",
    "\n",
    "TODO:\n",
    "- fix bundle == max_commits\n",
    "- split git functions into another class\n",
    "- add user config method\n",
    "- account for revisions not being found\n",
    "- convert to `.py` for CLI use\n",
    "- fix recursive functions holding terminal output in argument line\n",
    "\n",
    "\n",
    "- COMPLETE: add folder/file ignore features\n",
    "- COMPLETE: enable use of folder ID from Google Drive rather than using `folder`\n",
    "- COMPLETE: use only the last bundle of files per commit\n",
    "- COMPLETE: fix bundle commits to be committed on last date, rather than first\n",
    "- COMPLETE: bundle commits oldest to newest (to prevent older versions overwriting newer ones within bundles)\n",
    "- REMOVED: sync file ignore and gitignore (split between ignore_folders and ignore_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d54819b-412a-41ca-8df4-ba3d0280ed3b",
   "metadata": {
    "id": "6d54819b-412a-41ca-8df4-ba3d0280ed3b"
   },
   "source": [
    "Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f3663-9195-43c9-8916-dd71bf44cfa2",
   "metadata": {
    "id": "b28f3663-9195-43c9-8916-dd71bf44cfa2"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "import time\n",
    "import pytz\n",
    "import datetime\n",
    "import git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b304da-a9ca-44ce-8ea9-61b5cff1beb9",
   "metadata": {
    "id": "70b304da-a9ca-44ce-8ea9-61b5cff1beb9"
   },
   "source": [
    "Google API class (based on `quickstart.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd2173-0ae3-404e-aa64-7cfb07ebf85e",
   "metadata": {
    "id": "5abd2173-0ae3-404e-aa64-7cfb07ebf85e"
   },
   "outputs": [],
   "source": [
    "class GoogleDrive:\n",
    "    def __init__(self):\n",
    "        # delete token.json before changing these\n",
    "        self.scopes = [\n",
    "            # 'https://www.googleapis.com/auth/drive.metadata.readonly',\n",
    "            'https://www.googleapis.com/auth/drive.readonly'\n",
    "        ]\n",
    "        self.creds = None\n",
    "        self.credentials()\n",
    "        self.connect()\n",
    "    \n",
    "    def credentials(self):\n",
    "        # store credentials (user access and refresh tokens)\n",
    "        if os.path.exists('token.json'):\n",
    "            self.creds = Credentials.from_authorized_user_file('token.json', self.scopes)\n",
    "        # if no (valid) credentials available, let user log in\n",
    "        if not self.creds or not self.creds.valid:\n",
    "            if self.creds and self.creds.expired and self.creds.refresh_token:\n",
    "                self.creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file('credentials.json', self.scopes)\n",
    "                self.creds = flow.run_local_server()  # port MUST match redirect URI in Google App\n",
    "            # save credentials for the next run\n",
    "            with open('token.json', 'w') as token:\n",
    "                token.write(self.creds.to_json())\n",
    "                \n",
    "    def connect(self):\n",
    "        # attempt to connect to the API\n",
    "        try:\n",
    "            self.service = build('drive', 'v3', credentials=self.creds)\n",
    "            # self.service = build('gmail', 'v1', credentials=self.creds)  # use later for gmail...\n",
    "        except HttpError as error:\n",
    "            print(f'An error occurred: {error}')\n",
    "            \n",
    "    def id_get(self, i):\n",
    "        r = self.service.files().get(fileId=i).execute()\n",
    "        \n",
    "        return r\n",
    "            \n",
    "    def id_search(self, values, term='name', operator='=', ftype='file', ignore_trashed=True):\n",
    "        q = f'{term} {operator} \"{values}\" '\n",
    "        if ftype == 'folder':\n",
    "            q += 'and mimeType = \"application/vnd.google-apps.folder\" '\n",
    "        elif ftype == 'json':\n",
    "            q += 'and mimeType = \"application/json\" '\n",
    "        if ignore_trashed:\n",
    "            q += 'and trashed = false'\n",
    "        l = self.service.files().list(q=q).execute()\n",
    "        \n",
    "        return l['files']\n",
    "            \n",
    "    def folder_contents(self, i, ignore_trashed=True):\n",
    "        q = f'\"{i}\" in parents '\n",
    "        if ignore_trashed:\n",
    "            q += 'and trashed = false '\n",
    "        l = self.service.files().list(q=q).execute()\n",
    "        \n",
    "        return l['files']\n",
    "            \n",
    "    def get_revisions(self, i):\n",
    "        try:\n",
    "            r = self.service.revisions().list(fileId=i).execute()\n",
    "        \n",
    "            return r['revisions']\n",
    "        \n",
    "        except:\n",
    "            return\n",
    "        \n",
    "    def qry_fields(self, i, r=None, fields=['parents']):\n",
    "        if r is None:\n",
    "            p = self.service.files().get(fileId=i, fields=','.join(fields)).execute()\n",
    "        else:\n",
    "            p = self.service.revisions().get(fileId=i, revisionId=r, fields=','.join(fields)).execute()\n",
    "        \n",
    "        return {f: p[f] for f in fields}\n",
    "    \n",
    "    def stream_file(self, i, r=None, out='stream', verbose=False):\n",
    "        if r is None:\n",
    "            request = self.service.files().get_media(fileId=i)\n",
    "        else:\n",
    "            request = self.service.revisions().get_media(fileId=i, revisionId=r)\n",
    "        \n",
    "        if out in ['stream', 'str']:\n",
    "            stream = io.BytesIO()\n",
    "        else:\n",
    "            stream = io.FileIO(out, mode='w')\n",
    "        downloader = MediaIoBaseDownload(stream, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            if verbose:\n",
    "                print(f'Download {int(status.progress() * 100)}%')\n",
    "        if verbose:\n",
    "            print(f'Size {status.total_size / 1024 / 1024:.2f}MB')\n",
    "\n",
    "        if out in ['str']:\n",
    "            return stream.getvalue()\n",
    "        else:\n",
    "            return stream\n",
    "\n",
    "    \n",
    "class Drive2Git:\n",
    "    def __init__(self, drive, folder, local_path=os.getcwd(), ignore_folders=[], ignore_files=[]):\n",
    "        self.drive = drive\n",
    "        self.folder = self.check_object(folder)\n",
    "        self.local_path = local_path\n",
    "        self.ignore_folders = ignore_folders\n",
    "        self.ignore_files = ignore_files\n",
    "        self.folder_map = self.map_folder(folder)\n",
    "    \n",
    "    def check_object(self, obj):\n",
    "        # check case: id\n",
    "        if type(obj) == str:\n",
    "            print('Getting object info using ID.')\n",
    "            obj = self.drive.id_get(obj)\n",
    "        elif type(obj) == list:\n",
    "            print('Getting object info from first list item.')\n",
    "            \n",
    "        return obj\n",
    "    \n",
    "    def check_ignore(self, obj, ignorances):\n",
    "        flag = False\n",
    "        if obj['name'] in ignorances:\n",
    "            flag = True\n",
    "            \n",
    "        return flag\n",
    "        \n",
    "    def map_folder(self, folder, path=''):\n",
    "        '''\n",
    "        Recursive.\n",
    "        '''\n",
    "        # check if id used\n",
    "        folder = self.check_object(folder)\n",
    "        \n",
    "        # if root, set path to folder name\n",
    "        if path == '':\n",
    "            path = folder['name']\n",
    "\n",
    "        # scan contents\n",
    "        contents = []\n",
    "        for c in self.drive.folder_contents(folder['id']):\n",
    "            if c['mimeType'] == 'application/vnd.google-apps.folder':\n",
    "                p = os.path.join(path, c['name'])\n",
    "                contents.append(self.map_folder(c, path=p))\n",
    "            else:\n",
    "                f = {\n",
    "                    'path': os.path.join(path, c['name']),\n",
    "                    'id': c['id'],\n",
    "                    'name': c['name'],\n",
    "                    'type': c['mimeType'],\n",
    "                    'gitignore': self.check_ignore(folder, self.ignore_folders) | self.check_ignore(c, self.ignore_files),\n",
    "                    'revisions': self.drive.get_revisions(c['id'])\n",
    "                }\n",
    "                contents.append(f)\n",
    "                \n",
    "        # set up output dictionary\n",
    "        out = {\n",
    "            'path': path,\n",
    "            'id': folder['id'],\n",
    "            'name': folder['name'],\n",
    "            'type': folder['mimeType'],\n",
    "            'gitignore': self.check_ignore(folder, self.ignore_folders),\n",
    "            'contents': contents\n",
    "        }\n",
    "                \n",
    "        return out\n",
    "    \n",
    "    def create_folders(self, folder_map):\n",
    "        '''\n",
    "        Recursive.\n",
    "        '''\n",
    "        # create \"root\" folder\n",
    "        try:\n",
    "            os.mkdir(os.path.join(self.local_path, folder_map['path']))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # map folder\n",
    "        for c in folder_map['contents']:\n",
    "            if 'contents' in c.keys():\n",
    "                self.create_folders(c)\n",
    "    \n",
    "    def delete_folders(self, path):\n",
    "        for root, dirs, files in os.walk(path, topdown=False):\n",
    "            for name in files:\n",
    "                os.remove(os.path.join(root, name))\n",
    "            for name in dirs:\n",
    "                os.rmdir(os.path.join(root, name))\n",
    "    \n",
    "    def itemize_revisions(self, folder_map, revisions={}):\n",
    "        '''\n",
    "        Recursive.\n",
    "        '''\n",
    "        for c in folder_map['contents']:\n",
    "            if c['type'] == 'application/vnd.google-apps.folder':\n",
    "                revisions = self.itemize_revisions(c, revisions=revisions)\n",
    "            else:\n",
    "                if 'revisions' in c.keys():\n",
    "                    if len(c['revisions']) >= 100:\n",
    "                        print(f'Warning: maximum number of Google Drive revisions used or exceeded by {c[\"name\"]}.')\n",
    "                    for i, r in enumerate(c['revisions']):\n",
    "                        revision = {\n",
    "                            'path': c['path'],\n",
    "                            'id': c['id'],\n",
    "                            'rid': r['id'],\n",
    "                            'name': c['name'],\n",
    "                            'gitignore': c['gitignore'],\n",
    "                            'version': i + 1\n",
    "                        }\n",
    "                        k = r['modifiedTime']\n",
    "                        v = revisions.get(k, [])\n",
    "                        if revision['rid'] not in [i['rid'] for i in v]:  # avoids duplicates if rerun\n",
    "                            v.append(revision)\n",
    "                            revisions.update({k: v})\n",
    "\n",
    "        return revisions\n",
    "    \n",
    "    def bundle_commits(self, minutes=240):\n",
    "        # get commits\n",
    "        commits = self.itemize_revisions(self.folder_map)\n",
    "        dates = sorted(commits)\n",
    "\n",
    "        # set time zones\n",
    "        utc = pytz.timezone('UTC')\n",
    "        tz = pytz.timezone('US/Eastern')\n",
    "\n",
    "        # initialize variables\n",
    "        bundle = {}\n",
    "        rdates = []\n",
    "        cdates = []\n",
    "        comms = []\n",
    "\n",
    "        # loop through sorted dates\n",
    "        while len(dates) > 0:\n",
    "            rdate = dates.pop(0)  # oldest -> newest\n",
    "            parsed_date = datetime.datetime.strptime(rdate, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "            cdate = utc.localize(parsed_date).astimezone(tz)\n",
    "            com = commits.get(rdate)\n",
    "\n",
    "            # existing bundle\n",
    "            if len(cdates) > 0:\n",
    "                # within bundle threshold\n",
    "                if (cdate - cdates[-1]).total_seconds() / 60 < minutes:  # time from previous edit\n",
    "                    # grow bundle\n",
    "                    rdates.append(rdate)\n",
    "                    cdates.append(cdate)\n",
    "                    comms += com  # extend list\n",
    "                else:\n",
    "                    # append previous bundle\n",
    "                    bundle.update({rdates[-1]: {\n",
    "                        'cdate': cdates[-1],\n",
    "                        # 'rdates': rdates,\n",
    "                        'files': comms\n",
    "                    }})\n",
    "                    \n",
    "                    # start new bundle\n",
    "                    rdates = [rdate]\n",
    "                    cdates = [cdate]\n",
    "                    comms = com\n",
    "                if len(dates) == 0:\n",
    "                    # append final bundle\n",
    "                    bundle.update({rdates[-1]: {\n",
    "                        'cdate': cdates[-1],\n",
    "                        # 'rdates': rdates,\n",
    "                        'files': comms\n",
    "                    }})\n",
    "            else:\n",
    "                # start new bundle\n",
    "                rdates = [rdate]\n",
    "                cdates = [cdate]\n",
    "                comms = com\n",
    "\n",
    "        # sort bundle by keys\n",
    "        self.bundle = dict(sorted(bundle.items()))\n",
    "    \n",
    "    def max_versions(self):\n",
    "        bundle = self.bundle.copy()\n",
    "\n",
    "        for _, v in bundle.items():\n",
    "            commits = v['files']\n",
    "            max_versions = {}\n",
    "            for c in commits:\n",
    "                i = max_versions.get(c['id'], {})\n",
    "                if len(i) == 0:\n",
    "                    max_versions.update({c['id']: c})\n",
    "                else:\n",
    "                    if c['version'] > i['version']:\n",
    "                        max_versions.update({c['id']: c})\n",
    "\n",
    "            v['files'] = list(max_versions.values())\n",
    "\n",
    "        self.max_commits = bundle\n",
    "        \n",
    "    def gitignore(self, name):\n",
    "        file_path = os.path.join(self.local_path, name, '.gitignore')\n",
    "        \n",
    "        # remove old .gitignore file\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "            \n",
    "        # add new .gitignore file\n",
    "        files = self.ignore_folders + self.ignore_files\n",
    "        with open(file_path, 'w') as f:\n",
    "            lines = [f'**/{l}\\n' for l in files]\n",
    "            f.writelines(lines)\n",
    "    \n",
    "    def make_repo(self, minutes=240):\n",
    "        # get name and commit info\n",
    "        name = self.folder_map['path']\n",
    "        self.bundle_commits(minutes)\n",
    "        self.max_versions()\n",
    "        \n",
    "        # remove any existing git folders\n",
    "        git_path = os.path.join(self.local_path, name, '.git')\n",
    "        if os.path.isdir(git_path):\n",
    "            self.delete_folders(git_path)\n",
    "            print('Old git folder removed.\\n')\n",
    "\n",
    "        # configure git repo\n",
    "        print('Configuring git repo.')\n",
    "        repo = git.Repo.init(os.path.join(self.local_path, name), expand_vars=False)\n",
    "        author = git.Actor(name='Craig N', email='7h47ch@gmail.com')\n",
    "        utc = pytz.timezone('UTC')\n",
    "        tz = pytz.timezone('US/Eastern')\n",
    "\n",
    "        # create folders - move up???\n",
    "        print('Creating folder structure.\\n')\n",
    "        self.create_folders(self.folder_map)\n",
    "\n",
    "        # auto-commits\n",
    "        for i, (k, v) in enumerate(self.max_commits.items()):\n",
    "            # make files\n",
    "            cdate = v['cdate']\n",
    "            files = v['files']\n",
    "            print(f'Auto-commit {i+1}, adding {len(files)} updates bundled from {k}...')\n",
    "            for f in files:\n",
    "                file_path = os.path.join(self.local_path, f['path'])\n",
    "                print(f'\\t{f[\"path\"]}, v{f[\"version\"]}')\n",
    "                try:\n",
    "                    self.stream_file(f['id'], r=f['rid'], out=file_path)\n",
    "                except:\n",
    "                    print('\\t\\tFile error!')\n",
    "\n",
    "                # add file\n",
    "                if not f['gitignore']:\n",
    "                    repo.index.add([file_path])\n",
    "                else:\n",
    "                    print(f'\\t\\tNot added to commit.')\n",
    "                    \n",
    "            # add gitignore\n",
    "            self.gitignore(name)\n",
    "            ignore_path = os.path.join(self.local_path, name, '.gitignore')\n",
    "            repo.index.add([ignore_path])\n",
    "            \n",
    "            repo.index.commit(f'Auto-commit {i+1} (via Google Drive-to-git tool).', author=author, committer=author,\n",
    "                              author_date=cdate, commit_date=cdate)  # add author or committer args\n",
    "            \n",
    "        print(f'\\nNew git folder written!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc79cc-d806-42b8-b480-330cad753a28",
   "metadata": {
    "id": "abbc79cc-d806-42b8-b480-330cad753a28"
   },
   "source": [
    "## Commit to new `git` repo\n",
    "The GitPython package is as lazy as possible meaning that it takes arguments from existing git environmental variables where possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0eae73-d36b-4dd4-a14b-d95b187b73f5",
   "metadata": {
    "id": "ee0eae73-d36b-4dd4-a14b-d95b187b73f5"
   },
   "source": [
    "Connect to API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194e137-0a7f-4a80-a1ac-425b912a5d9f",
   "metadata": {
    "id": "7194e137-0a7f-4a80-a1ac-425b912a5d9f"
   },
   "outputs": [],
   "source": [
    "drive = GoogleDrive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8289f846-86c2-4de2-b488-2875a41dafbd",
   "metadata": {},
   "source": [
    "Scout folders, files, and revisions and create git repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7f915d-30c2-441a-97e1-fad35124ab2a",
   "metadata": {
    "id": "9c7f915d-30c2-441a-97e1-fad35124ab2a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# folder = drive.id_search('google_workspace', ftype='folder')[0]\n",
    "folder = drive.id_get('10oJBulB5E6_zdBhuuV6Qk41yTWPKoo8D')\n",
    "\n",
    "g = Drive2Git(drive, folder, local_path='C:\\\\Users\\\\7h47c\\\\Desktop',\n",
    "            ignore_folders=['.ipynb_checkpoints'],\n",
    "            ignore_files=['credentials.json','token.json'])\n",
    "\n",
    "g.make_repo()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "google_apis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
